{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "\n",
        "# Load the dataset\n",
        "file_path = 'TARP[1].csv'\n",
        "names = ['Soil Moisture', 'Temperature', 'Soil Humidity', 'Time', 'Air temperature (C)', 'Wind speed (Km/h)',\n",
        "         'Air humidity (%)', 'Wind gust (Km/h)', 'Pressure (KPa)', 'ph', 'rainfall', 'N', 'P', 'K', 'status']\n",
        "data = pd.read_csv(file_path, names=names, header=0)\n",
        "\n",
        "# Data preprocessing\n",
        "data=data.drop(['Pressure (KPa)', 'ph', 'rainfall', 'N', 'P', 'K'],axis=1)\n",
        "print(data.describe())\n",
        "print(data.head())\n",
        "print(data.tail())\n",
        "data = data.ffill(limit=3)\n",
        "data = data.interpolate(method='linear', limit_direction='both')\n",
        "data['status'] = data['status'].map({'ON': 1, 'OFF': 0})\n",
        "\n",
        "# One-hot encoding for 'status' column\n",
        "encoder = OneHotEncoder(drop='first', sparse=False)\n",
        "status_encoded = encoder.fit_transform(data[['status']])\n",
        "status_df = pd.DataFrame(status_encoded, columns=['status_1'])\n",
        "data = pd.concat([data, status_df], axis=1)\n",
        "data.drop('status', axis=1, inplace=True)\n",
        "\n",
        "# MinMax scaling for 'Time' feature to a range of 0 to 60\n",
        "#time_scaler = MinMaxScaler(feature_range=(0, 60))\n",
        "#data['Time'] = time_scaler.fit_transform(data[['Time']])\n",
        "print(data.describe())\n",
        "print(data.head())\n",
        "print(data.tail())\n",
        "# Correlation matrix\n",
        "correlation_matrix = data.corr()\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
        "plt.title(\"Correlation Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# Exploratory data analysis\n",
        "# Bar plot for 'status' counts\n",
        "status_counts = data['status_1'].value_counts()\n",
        "plt.bar(status_counts.index, status_counts.values)\n",
        "plt.xticks(status_counts.index, ['OFF', 'ON'])  # Optional labeling for x-axis\n",
        "plt.title(\"Count of Status\")\n",
        "plt.xlabel(\"Status\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()\n",
        "\n",
        "# Box plots\n",
        "plt.figure(figsize=(15, 8))\n",
        "sns.boxplot(x='status_1', y='Soil Moisture', data=data)\n",
        "plt.title(\"Box Plot of Soil Moisture by Status\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(15, 8))\n",
        "sns.boxplot(x='status_1', y='Temperature', data=data)\n",
        "plt.title(\"Box Plot of Temperature by Status\")\n",
        "plt.show()\n",
        "\n",
        "# Correlation with target variable\n",
        "correlation_with_target = data.corr()['status_1'].drop('status_1')\n",
        "correlation_with_target.plot(kind='bar', figsize=(12, 6))\n",
        "plt.title(\"Correlation of Features with Status\")\n",
        "plt.ylabel(\"Correlation\")\n",
        "plt.xlabel(\"Features\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GrrJl2H1FfPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "lhOBAzCtac7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model training and evaluation\n",
        "start=time.time()\n",
        "X = data.iloc[:, :-1].values\n",
        "y = data[\"status_1\"].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=11111)\n",
        "rf_model = RandomForestClassifier(n_estimators=200)\n",
        "rf_model.fit(X_train, y_train)\n",
        "y_pred_class_rf = rf_model.predict(X_test)\n",
        "y_pred_prob_rf = rf_model.predict_proba(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred_class_rf)\n",
        "precision = precision_score(y_test, y_pred_class_rf)\n",
        "recall = recall_score(y_test, y_pred_class_rf)\n",
        "f1 = f1_score(y_test, y_pred_class_rf)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_prob_rf[:, 1])\n",
        "end=time.time()\n",
        "# Print performance metrics\n",
        "print(\"Accuracy: {:.3f}\".format(accuracy))\n",
        "print(\"Precision: {:.3f}\".format(precision))\n",
        "print(\"Recall: {:.3f}\".format(recall))\n",
        "print(\"F1 Score: {:.3f}\".format(f1))\n",
        "print(\"AUC: {:.3f}\".format(roc_auc))\n",
        "print(\"Execution time: {:.3f}\".format(end-start))\n",
        "# Plot ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob_rf[:, 1])\n",
        "plt.plot(fpr, tpr, 'b-')\n",
        "plt.plot([0, 1], [0, 1], 'r--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FfApqXY_Fx_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Model training and evaluation\n",
        "start=time.time()\n",
        "X = data.iloc[:, :-1].values\n",
        "y = data[\"status_1\"].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=11111)\n",
        "\n",
        "lr_model = LinearRegression()\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = lr_model.predict(X_test)\n",
        "# Evaluation metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "end=time.time()\n",
        "# Print performance metrics\n",
        "print(\"Mean Squared Error (MSE): {:.3f}\".format(mse))\n",
        "print(\"Root Mean Squared Error (RMSE): {:.3f}\".format(rmse))\n",
        "print(\"R^2 Score: {:.3f}\".format(r2))\n",
        "print(\"Execution time: {:.3f}\".format(end-start))"
      ],
      "metadata": {
        "id": "Na1-MxL1HjUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Model training and evaluation\n",
        "start=time.time()\n",
        "X = data.iloc[:, :-1].values\n",
        "y = data[\"status_1\"].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=11111)\n",
        "\n",
        "dt_model = DecisionTreeClassifier()\n",
        "dt_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_class_dt = dt_model.predict(X_test)\n",
        "y_pred_prob_dt = dt_model.predict_proba(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred_class_dt)\n",
        "precision = precision_score(y_test, y_pred_class_dt)\n",
        "recall = recall_score(y_test, y_pred_class_dt)\n",
        "f1 = f1_score(y_test, y_pred_class_dt)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_prob_dt[:, 1])\n",
        "end=time.time()\n",
        "# Print performance metrics\n",
        "print(\"Accuracy: {:.3f}\".format(accuracy))\n",
        "print(\"Precision: {:.3f}\".format(precision))\n",
        "print(\"Recall: {:.3f}\".format(recall))\n",
        "print(\"F1 Score: {:.3f}\".format(f1))\n",
        "print(\"AUC: {:.3f}\".format(roc_auc))\n",
        "print(\"Execution time: {:.3f}\".format(end-start))\n",
        "\n",
        "# Plot ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob_dt[:, 1])\n",
        "plt.plot(fpr, tpr, 'b-')\n",
        "plt.plot([0, 1], [0, 1], 'r--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "hopBnz_jJWkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Model training and evaluation\n",
        "start=time.time()\n",
        "X = data.iloc[:, :-1].values\n",
        "y = data[\"status_1\"].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=11111)\n",
        "\n",
        "svm_model = SVC(probability=True)\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_class_svm = svm_model.predict(X_test)\n",
        "y_pred_prob_svm = svm_model.predict_proba(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred_class_svm)\n",
        "precision = precision_score(y_test, y_pred_class_svm)\n",
        "recall = recall_score(y_test, y_pred_class_svm)\n",
        "f1 = f1_score(y_test, y_pred_class_svm)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_prob_svm[:, 1])\n",
        "end=time.time()\n",
        "# Print performance metrics\n",
        "print(\"Accuracy: {:.3f}\".format(accuracy))\n",
        "print(\"Precision: {:.3f}\".format(precision))\n",
        "print(\"Recall: {:.3f}\".format(recall))\n",
        "print(\"F1 Score: {:.3f}\".format(f1))\n",
        "print(\"AUC: {:.3f}\".format(roc_auc))\n",
        "print(\"Execution time: {:.3f}\".format(end-start))\n",
        "\n",
        "# Plot ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob_svm[:, 1])\n",
        "plt.plot(fpr, tpr, 'b-')\n",
        "plt.plot([0, 1], [0, 1], 'r--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "POidk0ZHJcUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Model training and evaluation\n",
        "start=time.time()\n",
        "X = data.iloc[:, :-1].values\n",
        "y = data[\"status_1\"].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=11111)\n",
        "\n",
        "sgd_model = SGDClassifier()\n",
        "sgd_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_class_sgd = sgd_model.predict(X_test)\n",
        "y_pred_prob_sgd = sgd_model.decision_function(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred_class_sgd)\n",
        "precision = precision_score(y_test, y_pred_class_sgd)\n",
        "recall = recall_score(y_test, y_pred_class_sgd)\n",
        "f1 = f1_score(y_test, y_pred_class_sgd)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_prob_sgd)\n",
        "end=time.time()\n",
        "# Print performance metrics\n",
        "print(\"Accuracy: {:.3f}\".format(accuracy))\n",
        "print(\"Precision: {:.3f}\".format(precision))\n",
        "print(\"Recall: {:.3f}\".format(recall))\n",
        "print(\"F1 Score: {:.3f}\".format(f1))\n",
        "print(\"AUC: {:.3f}\".format(roc_auc))\n",
        "print(\"Execution time: {:.3f}\".format(end-start))\n",
        "\n",
        "# Plot ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob_sgd)\n",
        "plt.plot(fpr, tpr, 'b-')\n",
        "plt.plot([0, 1], [0, 1], 'r--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0UDksPaSJ4Wy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Splitting the data into training and testing sets\n",
        "start=time.time()\n",
        "X = data.iloc[:, :-1].values\n",
        "y = data[\"status_1\"].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=11111)\n",
        "\n",
        "# Training the Naive Bayes classifier\n",
        "nb_model = GaussianNB()\n",
        "nb_model.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions on the test set\n",
        "y_pred = nb_model.predict(X_test)\n",
        "\n",
        "# Calculating performance metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "end=time.time()\n",
        "# Printing the performance metrics\n",
        "print(\"Accuracy: {:.3f}\".format(accuracy))\n",
        "print(\"Precision: {:.3f}\".format(precision))\n",
        "print(\"Recall: {:.3f}\".format(recall))\n",
        "print(\"F1 Score: {:.3f}\".format(f1))\n",
        "print(\"Execution time: {:.3f}\".format(end-start))"
      ],
      "metadata": {
        "id": "hL5KZ4MdQLDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score, precision_score, recall_score, f1_score\n",
        "from tensorflow import keras\n",
        "start=time.time()\n",
        "# Splitting the data into training and testing sets\n",
        "X = data.iloc[:, :-1].values\n",
        "y = data[\"status_1\"].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=11111)\n",
        "\n",
        "# Creating a neural network model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    keras.layers.Dense(64, activation='relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Training the model\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=32)\n",
        "\n",
        "# Predicting probabilities for the positive class (class 1)\n",
        "y_pred_prob = model.predict(X_test)\n",
        "y_pred = np.round(y_pred_prob).flatten()  # Convert probabilities to binary labels\n",
        "\n",
        "# Calculating the AUC\n",
        "auc = roc_auc_score(y_test, y_pred_prob)\n",
        "\n",
        "# Calculating performance metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "end=time.time()\n",
        "# Printing the performance metrics\n",
        "print(\"Accuracy: {:.3f}\".format(accuracy))\n",
        "print(\"Precision: {:.3f}\".format(precision))\n",
        "print(\"Recall: {:.3f}\".format(recall))\n",
        "print(\"F1 Score: {:.3f}\".format(f1))\n",
        "print(\"Execution time: {:.3f}\".format(end-start))\n",
        "# Plotting the ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
        "plt.plot(fpr, tpr, 'b-')\n",
        "plt.plot([0, 1], [0, 1], 'r--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "mrxNrFxiPyny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "start=time.time()\n",
        "# Splitting the data into training and testing sets\n",
        "X = data.iloc[:, :-1].values\n",
        "y = data.iloc[:, -1].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=11111)\n",
        "\n",
        "# Reshape the input data for LSTM (assuming time series data)\n",
        "input_shape = (X_train.shape[1], 1)\n",
        "X_train = X_train.reshape(X_train.shape[0], *input_shape)\n",
        "X_test = X_test.reshape(X_test.shape[0], *input_shape)\n",
        "\n",
        "# Creating an LSTM model\n",
        "model = keras.Sequential([\n",
        "    layers.LSTM(64, input_shape=input_shape),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Training the model\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=32)\n",
        "\n",
        "# Predicting probabilities for the positive class (class 1)\n",
        "y_pred_prob = model.predict(X_test)\n",
        "\n",
        "# Calculating the AUC\n",
        "auc = roc_auc_score(y_test, y_pred_prob)\n",
        "print(\"AUC: {:.3f}\".format(auc))\n",
        "\n",
        "# Calculating performance metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "end=time.time\n",
        "# Printing the performance metrics\n",
        "print(\"Accuracy: {:.3f}\".format(accuracy))\n",
        "print(\"Precision: {:.3f}\".format(precision))\n",
        "print(\"Recall: {:.3f}\".format(recall))\n",
        "print(\"F1 Score: {:.3f}\".format(f1))\n",
        "print(\"Execution time: {:.3f}\".format(end-start))\n",
        "# Plotting the ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
        "plt.plot(fpr, tpr, 'b-')\n",
        "plt.plot([0, 1], [0, 1], 'r--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TrEEMNdlQOM5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}